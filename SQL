SQL uses CRUD operations...create,read,update,delete
SQL comprises of DQL data query lang(select), DDL data def language(create,alter,rename,truncate,drop), DML data manipulation lang(insert,update,delete), 
DCL data control lang(grant,revoke), TCL transaction control language(start,rollback,commit)

-> date ka datatype is DATE


CREATE DATABASE database_name;
CREATE DATABASE IF NOT EXISTS database_name;
DROP DATABASE database_name;
DROP DATABASE IF NOT EXISTS database_name;
USE database_name;
SHOW DATABASES;
SHOW TABLES;

CREATE TABLE table_name(col1 datatype const);
INSERT INTO table_name(col1,col2) VALUES(val1,val2);
DESCRIBE table_name;

SELECT * FROM table_name;

-> to create the structure of a table like some other table
CREATE TABLE IF NOT EXISTS table_name LIKE wanted_table_name;
CREATE TABLE IF NOT EXISTS table_name LIKE SELECT * FROM wanted_table_name; 

ALTER TABLE table_name ADD col_name datatype constraint;
ALTER TABLE table_name DROP col_name;

CREATE TABLE table_name(
id INT,
name  VARCHAR(50),
city VARCHAR(50),
PRIMARY KEY(id,name)
);

CREATE TABLE table_name(
id INT,
name  VARCHAR(50),
city VARCHAR(50),
PRIMARY KEY(id,name)
FOREIGN KEY(id) REFERENCES table_name2(corresponding_col_name)
);

CREATE TABLE table_name(
id INT UNIQUE AUTO_INCREMENT,
name  VARCHAR(50) NOT NULL,
city VARCHAR(50) DEFAULT 'Delhi',
PRIMARY KEY(id,name)
);


UPDATE table_name
SET city = 'Chandigarh'
WHERE city = 'Hyderabad';

UPDATE table_name
SET city = 'Chandigarh'
WHERE id = 4 OR city = 'Kolkata';

UPDATE table_name
SET city = 'Chandigarh',name = 'Rishin'
WHERE id = 3;
diff kinds of operrations we got =, <>(not equals), > , < < >=, <=


DELETE from table_name
WHERE id = 4;

INSERT INTO table_name VALUES(comma_seperated_values);
joh characters hai unko '' iske andar likhna hai

SELECT col1,col2 FROM table_name;
SELECT * FROM table_name;
SELECT TOP 5 * FROM table_name;

SELECT DISTINCT(col_name) FROM table_name;

SELECT * FROM emp 
WHERE loc LIKE 'c%'

SELECT * FROM emp 
WHERE loc NOT LIKE '_ _ _c'


CREATE TABLE city(
 id INT PRIMARY KEY,
 city VARCHAR(50),
 age INT,
 CONSTRAINT age_check CHECK (age >= 18 AND city = "Delhi")
);

CREATE TABLE newtab(
 age INT CHECK(age >= 18)
);

SELECT * FROM student 
WHERE marks BETWEEN 80 AND 90;

SELECT * FROM student 
WHERE city IN ("Delhi","Mumbai");

SELECT * FROM student 
WHERE city NOT IN ("Delhi","Mumbai");

-> limit clause sets an upper limit on the number of rows(tuples) to be returned
SELECT * FROM student 
LIMIT 3;

SELECT * FROM student 
ORDER BY city ASC;

-> if we want the data of top 3 students in class...so first by put it in decreasing order and then use limit clause to return the top 3 students
SELECT * FROM student 
ORDER BY marks DESC 
LIMIT 3;

-> aggregate functions ...count(),max(),min(),sum(),avg()

-> count no of students in each city
SELECT count(name),city
FROM student
GROUP BY city;

SELECT count(name),city,name
FROM student
GROUP BY city;
-> the above query is going to throw an error as name col is not specified in Group by clause

-> write the query to find avg marks in each city in asc order
SELECT city, AVG(marks) FROM student
GROUP BY city 
ORDER BY avg(marks) ASC;


SELECT mode, count(mode)
FROm table
GROUP BY mode;

SELECT count(name), city
FROM student
GROUP BY city
HAVING max(marks) > 90;

-> cascading means if there is a change in the child table then the change must be reflected in the parent table as well
CREATE TABLE table_name(
 id INT PRIMARY KEY,
 courseID INT,
 FOREIGN KEY (courseID) REFERENCES table_name2(id)
 ON DELETE CASCADE
 ON UPDATE CASCADE
);


ALTER TABLE table_name
ADD COLUMN column_name datatype constraints;

ALTER TABLE table_name
DROP COLUMN column_name;

-> table name change karne ke liye
ALTER TABLE table_name
RENAME TO new_table_name;

-> table mein koi col ka name change karne ke liye
ALTER TABLE table_name
CHANGE old_name new_name new_datatype new_constraints;

ALTER TABLE table_name
MODIFY column_name new_datatype new_constraint;

-> drop deletes the entire table but truncate deletes the data present in the table
TRUNCATE TABLE table_name;


-> joins
SELECT columns
FROM tableA
INNER JOIN tableB
ON tableA.col_name = tableB.col_name;

SELECT columns
FROM tableA
LEFT JOIN tableB
ON tableA.col_name = tableB.col_name;

SELECT columns
FROM tableA
RIGHT JOIN tableB
ON tableA.col_name = tableB.col_name;

-> saare table ko poori tarah join karne ke 2 methods
SELECT * FROM student AS a
LEFT JOIN course AS b
ON a.id = b.id
UNION
SELECT * FROM student AS a
RIGHT JOIN course AS b
ON a.id = b.id;

SELECT * FROM a
FULL OUTER JOIN b
ON a.key = b.key;


-> left exclusive join
SELECT * FROM student AS a
LEFT JOIN course AS B
ON a.id = b.id
WHERE b.id IS NULL;

-> right exclusive join
SELECT * FROM student AS a
RIGHT JOIN course AS B
ON a.id = b.id
WHERE a.id IS NULL;

-> full exclusive join
SELECT * FROM a
FULL OUTER JOIN b
ON a.key = b.key
WHERE a.key IS NULL OR b.key IS NULL;

-> self join
SELECT col
FROM table_name AS a
JOIN table_name AS b
ON a.key = b.key;


-> union removes duplicate values whereas union all keeps the duplicate values
SELECT name FROM emp
UNION
SELECT name from emp;

SELECT name FROM emp
UNION ALL
SELECT name from emp;

-> subqueries...use the operation like between or in 
-> find the employees whos salary is mor ethan the average salary
SELECT * FROM employee 
WHERE salary > (SELECT AVG(salary) FROM employee);

or

SELECT * FROM employee e
JOIN (SELECT AVG(salary) sal FROM employee) avg_sal
ON e.salary > avg_sal.sal;

-> scalar subquery will return one row and 1 column
-> multiple row subquery which returns ,ul col and mul rows or return 1 col and mul rows

-> find the emp who earn the highest salary in each dept

SELECT * FROM employee 
WHERE (dept_name, salary) IN (SELECT dept_name, max(salary) FROM employee
                             GROUP BY dept_name);

-> find dept who do not have any employees
SELECT * FROM department
WHERE dept_name NOT IN (SELECT DISTINCT(dept_name) FROM employee);

-> correlated subquery  


-> views
view is a virtual table based on the result-set of an SQL statement

CREATE VIEW view1 AS
SELECT roll, name FROM student;

SELECT * FROM view1;

single table
CREATE VIEW details AS
SELECT name,add
FROM students
WHERE id < 18;

multiple table
CREATE VIEW details AS
SELECT s.name,s.add,m.marks
FROM students s, marks m
WHERE s.id = m.id;

dropping view
DROP VIEW name;

###################
CASE(IF-ELSE)

SELECT N,
CASE
WHEN P IS NULL THEN 'Root'
WHEN N NOT IN (SELECT DISTINCT P FROM BST WHERE P IS NOT NULL) THEN 'Leaf'
ELSE 'Inner'
END
FROM BST
ORDER BY N;

#############################
CALCULATING MEDIAN

SELECT DISTINCT PERCENTILE_CONT(0.5) 
  WITHIN GROUP (ORDER BY list_price) OVER() AS "Median"
FROM sales.order_items

SELECT ROUND(AVG(LAT_N), 4) AS Median_Latitude
FROM (
    SELECT LAT_N
    FROM STATION
    ORDER BY LAT_N
    LIMIT 2 - (SELECT COUNT(*) FROM STATION) % 2, 1
) AS median_query;


tips
-> char aur varchar mein yeh diff hai ki char poora memory jitna bola hai utna retain kar dega ....lekin varchar joh hai woh utna hi memory lega jitni zarurat hai...
hence varchar is more memory efficient

-> BLOB datatype ka matlab hai binary large objects
-> Foreign Keys can have duplicate and null values
-> constraints = NULL, NOT NULL, UNIQUE, PRIMARY KEY, DEFAULT,AUTO_INCREMENT
-> modulus - MOD(col_name, number)....example - MOD(ID,2)=0...means even ID

-> Use WHERE instead of HAVING when filtering rows based on conditions related to columns (MARKS in this case). 
HAVING is used with aggregate functions (like SUM, COUNT, AVG) in GROUP BY queries.

-> Aggregate functions - SUM(),AVG(),DIFFERENCE().....yeh string ske liye hai, nos ke liye normal '-' sign
REPLACE(), ROUND(), CEIL(),FLOOR()

-> QUESTION
Query the two cities in STATION with the shortest and longest CITY names, as well as their respective lengths 
(i.e.: number of characters in the name). If there is more than one smallest or largest city, choose the one that
comes first when ordered alphabetically.

SELECT CITY, LENGTH(CITY)
FROM STATION
ORDER BY LENGTH(CITY) ASC, CITY ASC
LIMIT 1;

SELECT CITY, LENGTH(CITY)
FROM STATION
ORDER BY LENGTH(CITY) DESC, CITY ASC
LIMIT 1;

inplace of LIMIT 1 , one can also use FETCH FIRST ROW ONLY
pehle length se sort then alphabeticcaly sort isiliye order by ke baad ussi order mein mention karna imp


-> QUESTION
Query the list of CITY names ending with vowels (a, e, i, o, u) from STATION. Your result cannot contain duplicates.

SELECT DISTINCT CITY
FROM STATION
WHERE RIGHT(CITY,1) IN ('A', 'E', 'I', 'O', 'U', 'a', 'e', 'i', 'o', 'u');


right side se first character
aise hi left bhi rehta ... use it for extraction


#############################
WINDOWS FUNCTION

Operate on a "window" of rows defined by the OVER() clause
Don't group rows like GROUP BY - each row remains visible in the result 
GROUP BY collapses rows, while OVER() keeps all rows and spreads the result of an aggregation across them.
Can access other rows in the same result set
Often used for rankings, running totals, moving averages, and comparing rows


PARTITION BY	 --------------Groups rows into subsets for per-group calculations	-------Calculate department-specific metrics
ORDER BY	-------------------Sorts rows within partitions for sequencing---------------	Compute running totals or rankings


->
-- Total sales per region alongside individual transactions
SELECT 
  region,
  sale_amount,
  SUM(sale_amount) OVER (PARTITION BY region) AS regional_total
FROM sales;

Yahan pe uss table pe ek extra column add hoga named "regional_total" for each row
but if we use GROUP_BY() then rows will get collapsed


->

Compare rows to group averages/peaks:

-- Products exceeding category average price
SELECT 
  product_id,
  category,
  price,
  AVG(price) OVER (PARTITION BY category) AS category_avg
FROM products;


-> Ranking Functions - ROW_NUMBER() - Assigns a unique sequential integer to rows within a partition.
SELECT 
    employee_id,
    first_name,
    last_name,
    salary,
    ROW_NUMBER() OVER (ORDER BY salary DESC) as salary_rank
FROM employees;

RANK(): Leaves gaps in the ranking when there are ties
DENSE_RANK(): Doesn't leave gaps in the ranking

SELECT 
    product_id,
    product_name,
    price,
    RANK() OVER (ORDER BY price DESC) as rank_price,
    DENSE_RANK() OVER (ORDER BY price DESC) as dense_rank_price
FROM products;


-> Aggregate Functions

SELECT 
    order_id,
    customer_id,
    order_date,
    amount,
    SUM(amount) OVER (PARTITION BY customer_id) as customer_total,
    AVG(amount) OVER (PARTITION BY customer_id) as customer_avg,
    COUNT(*) OVER (PARTITION BY customer_id) as customer_orders
FROM orders;


-> Value Functions - FIRST_VALUE() and LAST_VALUE() - Get the first or last value in a window frame.

SELECT 
    department_id,
    employee_id,
    salary,
    FIRST_VALUE(employee_id) OVER (
        PARTITION BY department_id 
        ORDER BY salary DESC
    ) as highest_paid_emp,
    LAST_VALUE(employee_id) OVER (
        PARTITION BY department_id 
        ORDER BY salary DESC
        RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING
    ) as lowest_paid_emp
FROM employees;

UNBOUNDED PRECEDING: All rows from the start of the partition
UNBOUNDED FOLLOWING: All rows to the end of the partition
it makes the window function consider the entire partition for each calculation, regardless of the current row's position.


LAG() and LEAD() - Access data from previous or subsequent rows.

SELECT 
    date,
    revenue,
    LAG(revenue, 1) OVER (ORDER BY date) as prev_day_revenue,
    LEAD(revenue, 1) OVER (ORDER BY date) as next_day_revenue,
    revenue - LAG(revenue, 1) OVER (ORDER BY date) as daily_change
FROM daily_sales;


-> Statistical Functions - PERCENT_RANK(): Relative rank of a row (0 to 1) 
CUME_DIST(): Cumulative distribution (proportion of rows ≤ current row)

SELECT 
    student_id,
    test_score,
    PERCENT_RANK() OVER (ORDER BY test_score) as percentile,
    CUME_DIST() OVER (ORDER BY test_score) as cumulative_dist
FROM test_scores;

NTILE() - Divides rows into a specified number of approximately equal groups.
SELECT 
    customer_id,
    total_purchases,
    NTILE(4) OVER (ORDER BY total_purchases DESC) as quartile
FROM customer_stats;


->
SELECT 
    date,
    revenue,
    AVG(revenue) OVER (
        ORDER BY date
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    ) as three_day_moving_avg,
    SUM(revenue) OVER (
        ORDER BY date
        RANGE BETWEEN INTERVAL '7' DAY PRECEDING AND CURRENT ROW
    ) as seven_day_running_total
FROM daily_sales;


Moving Average or Rolling Average - Apne paas ek window hai aur uss window mein current row ke thode rows upar ya neeche ko consider karke hum log average nikalte
then the window shifts down and the average is re calculated

In the above code we are calculating 3 day moving average
current window size mein current row aur pichle 2 rows ka average nikalna hai

We are also calculating 7 days running total
RANGE BETWEEN INTERVAL '7' DAY PRECEDING AND CURRENT ROW: Defines a frame containing:
The current row
All rows where the date is within 7 days before the current row's date

ROW BETWEEN and RANGE BETWEEN mein difference yeh hai ki ROW BETWEEN mein Rows ke position ko lekr hoga
RANGE BETWEEN mein woh sepecific value column ko lekr hoga jaise idhar date tha
It will include all rows that fall within the date range, even if there are missing dates
If multiple rows have the same date, they're all included


->

analysis of employee salaries within each department

SELECT 
    department_id,
    employee_id,
    salary,
    ROUND(salary * 100.0 / SUM(salary) OVER (PARTITION BY department_id), 2) as salary_pct,
    salary - AVG(salary) OVER (PARTITION BY department_id) as diff_from_avg,
    RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as dept_rank
FROM employees
ORDER BY department_id, salary DESC;


ROUND(salary * 100.0 / SUM(salary) OVER (PARTITION BY department_id), 2) as salary_pct
Ki individual salary department salary ka kitna % hai

salary - AVG(salary) OVER (PARTITION BY department_id) as diff_from_avg
Shows how much more or less each employee earns compared to their department average

RANK() OVER (PARTITION BY department_id ORDER BY salary DESC) as dept_rank
Ranks employees by salary within their department (highest salary = rank 1)



->

SELECT 
    customer_id,
    order_date,
    amount,
    SUM(amount) OVER (
        PARTITION BY customer_id
        ORDER BY order_date
        ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW
    ) as running_total,
    LAG(amount, 1, 0) OVER (
        PARTITION BY customer_id
        ORDER BY order_date
    ) as prev_order_amount
FROM orders
ORDER BY customer_id, order_date;


we calculated running total - toh rows current wale au uske pehle tak ke hence - ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW
we calculated Previous Order Amount - LAG(amount, 1, 0): Looks back 1 row to get the previous amount (defaults to 0 if no previous row exists)



->

SELECT 
    department_id,
    employee_id,
    salary,
    RANK() OVER (PARTITION BY department_id ORDER BY salary) as dept_rank
FROM employees
WHERE 1=0;  -- No rows returned

Empty Result Set: The query will return zero rows because:
WHERE 1=0 is a false condition for all rows
This filters out all records before window functions are applied


->

SELECT 
    employee_id,
    RANK() OVER (ORDER BY NULL) as rank
FROM employees;

All rows get rank 1 since all are equivalent.


->

SELECT 
    product_id,
    category,
    sales,
    RANK() OVER (PARTITION BY category ORDER BY sales DESC) as category_rank,
    RANK() OVER (ORDER BY sales DESC) as overall_rank,
    sales - LAG(sales, 1, 0) OVER (PARTITION BY category ORDER BY month) as sales_growth
FROM product_sales;


->

RANGE BETWEEN mein by default yeh rehta hai - RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW

SELECT 
    date,
    revenue,
    LAST_VALUE(revenue) OVER (ORDER BY date) as last_revenue
FROM daily_sales;

This doesn't work as expected because the default frame only goes up to the current row.

SELECT 
    date,
    revenue,
    LAST_VALUE(revenue) OVER (
        ORDER BY date
        RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING
    ) as last_revenue
FROM daily_sales;


->

SELECT 
    student_id,
    test_score,
    test_score - AVG(test_score) OVER (
        RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING
    ) as diff_from_mean,
    test_score * 100.0 / MAX(test_score) OVER (
        RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING
    ) as percent_of_max
FROM exam_results;


->

SELECT *
FROM (
  SELECT 
    order_id,
    month,
    amount,
    ROW_NUMBER() OVER (
      PARTITION BY month 
      ORDER BY amount DESC
    ) AS rank
  FROM orders
) ranked_orders
WHERE rank <= 2;

Top 2 orders by amount each month


->

-- Unique email activity ranks with ROW_NUMBER() [3]
SELECT 
  from_user,
  COUNT(*) AS total_emails,
  ROW_NUMBER() OVER (ORDER BY COUNT(*) DESC) AS rank
FROM google_gmail_emails
GROUP BY from_user;

Rank karo sabse zyada total emails kis user ne bheje


->

-- Top 3 products per category by price
SELECT *
FROM (
  SELECT 
    product_name,
    category,
    price,
    RANK() OVER (PARTITION BY category ORDER BY price DESC) AS price_rank
  FROM products
) ranked
WHERE price_rank <= 3;


->

-- Sum of current + next row's sales [2]
SELECT 
  BusinessEntityID,
  SalesYTD,
  SUM(SalesYTD) OVER (
    ORDER BY SalesYear
    ROWS BETWEEN CURRENT ROW AND 1 FOLLOWING
  ) AS next_two_sales
FROM Sales.SalesPerson;

or

SELECT 
  BusinessEntityID,
  SalesYTD,
  SalesYTD + LEAD(SalesYTD,1) OVER(ORDER BY SalesYear) AS next_two_sales
FROM Sales.SalesPerson;



###############################
CTE - (Common Table Expressions)

Think of it as creating a temporary table just for that query, without storing anything in the database.
It is defined using the WITH keyword.

-> Basic Syntax
WITH cte_name (column1, column2, ...) AS (
    -- CTE query definition
    SELECT column1, column2, ...
    FROM table_name
    WHERE conditions
)
-- Main query that uses the CTE
SELECT *
FROM cte_name;



-> List employees whose salary is above the average salary.
WITH avg_salary AS (
// ek dummy tabke si bana li jahan pe avg sal hoga 
    SELECT AVG(salary) AS avg_sal
    FROM employees
)
SELECT name, salary
FROM employees
WHERE salary > (SELECT avg_sal FROM avg_salary);


-> Calculate average salary and find employees above average
WITH avg_sal AS(
  SELECT AVG(salary) as average_salary
  FROM employees
)
select * from employees
where salary > average_salary

This solution is wrong because The average_salary column only exists within the context of the avg_sal CTE, 
but you're trying to reference it directly in the main query's WHERE clause.


Sol1 -
WITH avg_sal AS(
  SELECT AVG(salary) as average_salary
  FROM employees
)
SELECT e.*, a.average_salary
FROM employees e
CROSS JOIN avg_sal a
WHERE e.salary > a.average_salary;

SOl2 -
WITH avg_sal AS(
  SELECT AVG(salary) as average_salary
  FROM employees
)
SELECT * FROM employees
WHERE salary > (SELECT average_salary FROM avg_sal);

Sol3-
WITH avg_sal AS(
  SELECT AVG(salary) as average_salary
  FROM employees
)
SELECT e.*
FROM employees e, avg_sal a
WHERE e.salary > a.average_salary;



-> Find the top 3 highest-paid employees from each department.
WITH ranked AS (
// pehle rank karke ek table banaya jahan pe dept wise top 3 hai
    SELECT 
        name,
        department,
        salary,
        RANK() OVER (PARTITION BY department ORDER BY salary DESC) AS rnk
    FROM employees
),
top3 AS (
// upar wale table se ek aur table banaya jahan pe se sirf top 3 uthaye
    SELECT *
    FROM ranked
    WHERE rnk <= 3
)
SELECT * FROM top3;



-> This is a problem hierarchy - Get all employees under CEO, with levels
CEO (id=1)
 ├── Manager A (id=2)
 │     ├── Employee X (id=5)
 │     └── Employee Y (id=6)
 └── Manager B (id=3)
       └── Intern Z (id=7)



WITH numbered_days AS (
    SELECT 
        date,
        ROW_NUMBER() OVER (ORDER BY date) as row_num
    FROM attendance
    WHERE student_id = 123 AND present = true
)
SELECT 
    MIN(date) as start_date,
    MAX(date) as end_date,
    COUNT(*) as days_present
FROM (
    SELECT 
        date,
        date - row_num * INTERVAL '1 day' as grp
    FROM numbered_days
) t
GROUP BY grp
ORDER BY start_date;



->

-- Create test data with ties
WITH test_data AS (
    SELECT 1 as id, 100 as value UNION ALL
    SELECT 2, 100 UNION ALL
    SELECT 3, 200 UNION ALL
    SELECT 4, 200 UNION ALL
    SELECT 5, 300
)
SELECT 
    id,
    value,
    ROW_NUMBER() OVER (ORDER BY value) as row_num,
    RANK() OVER (ORDER BY value) as rank,
    DENSE_RANK() OVER (ORDER BY value) as dense_rank
FROM test_data;


->

WITH orders_cleaned AS (
  SELECT 
    order_id,
    customer_id,
    amount,
    ROW_NUMBER() OVER (
      PARTITION BY customer_id, order_date 
      ORDER BY order_id
    ) AS duplicate_flag
  FROM orders
)
SELECT * 
FROM orders_cleaned 
WHERE duplicate_flag = 1;

filtering duplicates


->

WITH customer_orders AS (
  SELECT 
    customer_id,
    order_date,
    amount,
    LAG(order_date) OVER (
      PARTITION BY customer_id 
      ORDER BY order_date
    ) AS prev_order_date
  FROM orders
)
SELECT 
  customer_id,
  order_date,
  prev_order_date,
  DATE_DIFF(order_date, prev_order_date, DAY) AS days_between_orders
FROM customer_orders;


Calculates time intervals between consecutive purchases



################################
SUBQUERIES




################################
DATE TIME MANIPULATION

| Function          | Description               | Example                                 |
| ----------------- | ------------------------- | --------------------------------------- |
| `NOW()`           | Current date and time     | `SELECT NOW();` → `2025-09-11 14:23:00` |
| `CURDATE()`       | Current date              | `SELECT CURDATE();` → `2025-09-11`      |
| `CURTIME()`       | Current time              | `SELECT CURTIME();` → `14:23:00`        |
| `UTC_TIMESTAMP()` | Current UTC date and time | `SELECT UTC_TIMESTAMP();`               |


| Function        | Description            | Example                                        |
| --------------- | ---------------------- | ---------------------------------------------- |
| `YEAR(date)`    | Extract year           | `SELECT YEAR('2025-09-11');` → `2025`          |
| `MONTH(date)`   | Extract month          | `SELECT MONTH('2025-09-11');` → `9`            |
| `DAY(date)`     | Extract day            | `SELECT DAY('2025-09-11');` → `11`             |
| `HOUR(time)`    | Extract hour           | `SELECT HOUR('14:23:00');` → `14`              |
| `MINUTE(time)`  | Extract minute         | `SELECT MINUTE('14:23:00');` → `23`            |
| `SECOND(time)`  | Extract second         | `SELECT SECOND('14:23:00');` → `0`             |
| `WEEKDAY(date)` | Day of week (0=Monday) | `SELECT WEEKDAY('2025-09-11');` → `3`          |
| `DAYNAME(date)` | Name of day            | `SELECT DAYNAME('2025-09-11');` → `'Thursday'` |


| Function                             | Description              | Example                                                           |
| ------------------------------------ | ------------------------ | ----------------------------------------------------------------- |
| `DATE_ADD(date, INTERVAL expr unit)` | Add interval             | `SELECT DATE_ADD('2025-09-11', INTERVAL 7 DAY);` → `2025-09-18`   |
| `DATE_SUB(date, INTERVAL expr unit)` | Subtract interval        | `SELECT DATE_SUB('2025-09-11', INTERVAL 1 MONTH);` → `2025-08-11` |
| `ADDDATE()`                          | Synonym for `DATE_ADD()` |                                                                   |
| `SUBDATE()`                          | Synonym for `DATE_SUB()` |                                                                   |


| Function                    | Description           | Example                                                                   |
| --------------------------- | --------------------- | ------------------------------------------------------------------------- |
| `DATE_FORMAT(date, format)` | Format date as string | `SELECT DATE_FORMAT(NOW(), '%Y-%m-%d %H:%i:%s');` → `2025-09-11 14:23:00` |


Common format codes:
%Y = 4-digit year
%y = 2-digit year
%m = 2-digit month
%d = 2-digit day
%H = 2-digit hour (24h)
%i = minutes
%s = seconds

| Function                   | Description          | Example                                                        |
| -------------------------- | -------------------- | -------------------------------------------------------------- |
| `STR_TO_DATE(str, format)` | Parse string to date | `SELECT STR_TO_DATE('11-09-2025', '%d-%m-%Y');` → `2025-09-11` |


| Function                                    | Description                  | Example                                                                               |
| ------------------------------------------- | ---------------------------- | ------------------------------------------------------------------------------------- |
| `DATEDIFF(date1, date2)`                    | Days between two dates       | `SELECT DATEDIFF('2025-09-11', '2025-09-01');` → `10`                                 |
| `TIMEDIFF(time1, time2)`                    | Difference between two times | `SELECT TIMEDIFF('14:23:00', '12:00:00');` → `02:23:00`                               |
| `TIMESTAMPDIFF(unit, datetime1, datetime2)` | Difference in specific units | `SELECT TIMESTAMPDIFF(MINUTE, '2025-09-11 12:00:00', '2025-09-11 14:00:00');` → `120` |


| Function                         | Description           | Example                                         |
| -------------------------------- | --------------------- | ----------------------------------------------- |
| `LAST_DAY(date)`                 | Last day of the month | `SELECT LAST_DAY('2025-09-11');` → `2025-09-30` |
| `MAKEDATE(year, day_of_year)`    | Create a date         | `SELECT MAKEDATE(2025, 254);` → `2025-09-11`    |
| `MAKETIME(hour, minute, second)` | Create time           | `SELECT MAKETIME(14, 23, 0);` → `14:23:00`      |
| `UTC_DATE()`                     | Current UTC date      | `SELECT UTC_DATE();`                            |


EXTRACT(unit FROM date)
SELECT EXTRACT(YEAR FROM '2025-09-11');        -- 2025
SELECT EXTRACT(MONTH FROM '2025-09-11');       -- 9
SELECT EXTRACT(DAY FROM '2025-09-11');         -- 11
SELECT EXTRACT(HOUR FROM '2025-09-11 14:23');  -- 14

Common Units:
YEAR
MONTH
DAY
HOUR
MINUTE
SECOND
WEEK
DAYOFWEEK
DAYOFYEAR
QUARTER


| SQL Server `DATENAME()`   | MySQL Equivalent  |
| ------------------------- | ----------------- |
| `DATENAME(WEEKDAY, date)` | `DAYNAME(date)`   |
| `DATENAME(MONTH, date)`   | `MONTHNAME(date)` |



###############################
NORMALISATION

Eliminate redundant data
Ensure data dependencies make sense
Reduce data modification anomalies
Simplify database structure

Problems Without Normalization:
Data Redundancy: Same data stored multiple times
Update Anomalies: Inconsistent data when updating
Insertion Anomalies: Cannot add data without other data
Deletion Anomalies: Loss of unrelated data when deleting


1. First Normal Form (1NF) - EASY
Rules:
Each table cell must contain a single value
Each record must be unique


2. Second Normal Form (2NF) - MEDIUM
Rules:
Must be in 1NF
All non-key attributes must depend on the entire primary key


3. Third Normal Form (3NF) - MEDIUM/HARD
Rules:
Must be in 2NF
No transitive dependencies (non-key attributes shouldn't depend on other non-key attributes)


4. Boyce-Codd Normal Form (BCNF) - HARD
Rules:
Must be in 3NF
For every functional dependency X → Y, X must be a superkey


5. Fourth Normal Form (4NF) - ADVANCED
Rules:
Must be in BCNF
No multi-valued dependencies


6. Fifth Normal Form (5NF) - EXPERT
Rules:
Must be in 4NF
No join dependencies



##############################
BROADCAST JOIN
A Broadcast Join is an optimization technique used in distributed computing frameworks (like Apache Spark) where the smaller of two tables is copied and
sent to every worker node that holds a part of the larger table, allowing the join to happen locally without shuffling the larger table.

Imagine you have two large tables in a distributed system:
orders (a huge table, partitioned across 100 machines)
customers (a medium-sized table, also partitioned across 100 machines)

If you want to join them on customer_id, the system needs to get all rows with the same customer_id onto the same machine. To do this, it performs a shuffle:
Each node looks at its data.
It sends each row to a different node based on a hash of the customer_id.
This involves moving massive amounts of data over the network, which is very slow and expensive.

A broadcast join works as follows:
The driver node (the coordinator) identifies the small table (e.g., customers).
It collects this entire small table and sends a copy of it to every single worker node that holds a partition of the large orders table.
Now, each worker node has:
Locally: Its own slice of the massive orders table.
Locally: A full copy of the entire customers table.
Each worker can now perform the join locally on its own machine, without needing to shuffle any data for the large orders table. This is extremely fast.

Think of a teacher with 30 students:
Shuffle Method:
"Everyone stand up and find the person with matching test answers" → chaos!
Broadcast Method:
Teacher gives everyone an answer key
"Check your work against this key" → fast and organized!
Broadcast Join is like giving every worker the "answer key" (small table) so they don't need to talk to each other.

